{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as model_selection\n",
    "from scipy import stats\n",
    "from keras.models import load_model\n",
    "\n",
    "NLPdata = pd.read_csv('nlpdata.csv')\n",
    "NLPdata = NLPdata.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, activation='selu', input_dim=2))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(5, activation='selu'))\n",
    "model.add(Dense(1, activation='linear')) \n",
    "#model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "model.summary()\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plswork():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    NLPdata = pd.read_csv('nlpdata.csv')\n",
    "    NLPdata = NLPdata.to_numpy()\n",
    "    model = load_model('my_model.h5')\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0:2], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "    X_train = X_train.reshape(-1,2)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    X_test = X_test.reshape(-1,2)\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run through 1\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 62/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 69/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 76/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 143/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 150/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 157/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 224/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 231/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 238/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0454\n",
      "Run through 2\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 62/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 69/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 76/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 143/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 150/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 157/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0454\n",
      "Epoch 164/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 224/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 231/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 245/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0453\n",
      "Run through 3\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 62/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 69/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 76/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 143/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 150/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 157/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 164/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 224/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 231/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 238/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 245/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "3/3 [==============================] - 0s 958us/step - loss: 0.0453\n",
      "Run through 4\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 62/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 69/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 76/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 143/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 150/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 157/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 164/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 224/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 231/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 238/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 245/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0453\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0453\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print('Run through', +i+1)\n",
    "    plswork()\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=250, verbose=1, validation_data=(X_test, y_test))\n",
    "    model.evaluate(X_test, y_test)\n",
    "    X_new = X_test\n",
    "    y_proba = model.predict(X_new)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.hist(y_proba, bins=20, histtype='step')\n",
    "    plt.savefig('hists4[i].png')            \n",
    "    #correlation = stats.pearsonr(y_proba.flatten(), y_test.flatten())[0]\n",
    "    #print(y_proba)\n",
    "    predict = np.vstack(y_proba)    \n",
    "    predictions = np.hstack(np.vstack(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1)\n",
      "(92, 1)\n",
      "(92,)\n"
     ]
    }
   ],
   "source": [
    "print(y_proba.shape)\n",
    "print(predict.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06021292]\n",
      " [0.10521755]\n",
      " [0.10131262]\n",
      " [0.14947279]\n",
      " [0.10131262]\n",
      " [0.10521755]\n",
      " [0.10131262]\n",
      " [0.08625   ]\n",
      " [0.07781741]\n",
      " [0.10131262]\n",
      " [0.06053511]\n",
      " [0.10521755]\n",
      " [0.16292463]\n",
      " [0.10131262]\n",
      " [0.10131262]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.08716822]\n",
      " [0.08716822]\n",
      " [0.08625   ]\n",
      " [0.19850883]\n",
      " [0.2358675 ]\n",
      " [0.08716822]\n",
      " [0.10131262]\n",
      " [0.11757129]\n",
      " [0.11757129]\n",
      " [0.08716822]\n",
      " [0.19850883]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.08625021]\n",
      " [0.08570638]\n",
      " [0.10131262]\n",
      " [0.06021292]\n",
      " [0.06164948]\n",
      " [0.05012817]\n",
      " [0.06870184]\n",
      " [0.06164948]\n",
      " [0.08625   ]\n",
      " [0.14947279]\n",
      " [0.01180483]\n",
      " [0.06870184]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.11589418]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.08570642]\n",
      " [0.06870184]\n",
      " [0.10131262]\n",
      " [0.08716822]\n",
      " [0.08716822]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.08716822]\n",
      " [0.11589418]\n",
      " [0.11757129]\n",
      " [0.11757129]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.10521755]\n",
      " [0.07781746]\n",
      " [0.19850859]\n",
      " [0.06021292]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.08716822]\n",
      " [0.10521755]\n",
      " [0.14947279]\n",
      " [0.11810686]\n",
      " [0.10521755]\n",
      " [0.09791354]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.06696659]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.11589418]\n",
      " [0.10131262]\n",
      " [0.09141472]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.14491954]\n",
      " [0.06021292]\n",
      " [0.06696659]\n",
      " [0.06870184]\n",
      " [0.11810686]\n",
      " [0.23520137]\n",
      " [0.11589418]]\n"
     ]
    }
   ],
   "source": [
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06021292]\n",
      " [0.10521755]\n",
      " [0.10131262]\n",
      " [0.14947279]\n",
      " [0.10131262]\n",
      " [0.10521755]\n",
      " [0.10131262]\n",
      " [0.08625   ]\n",
      " [0.07781741]\n",
      " [0.10131262]\n",
      " [0.06053511]\n",
      " [0.10521755]\n",
      " [0.16292463]\n",
      " [0.10131262]\n",
      " [0.10131262]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.08716822]\n",
      " [0.08716822]\n",
      " [0.08625   ]\n",
      " [0.19850883]\n",
      " [0.2358675 ]\n",
      " [0.08716822]\n",
      " [0.10131262]\n",
      " [0.11757129]\n",
      " [0.11757129]\n",
      " [0.08716822]\n",
      " [0.19850883]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.08625021]\n",
      " [0.08570638]\n",
      " [0.10131262]\n",
      " [0.06021292]\n",
      " [0.06164948]\n",
      " [0.05012817]\n",
      " [0.06870184]\n",
      " [0.06164948]\n",
      " [0.08625   ]\n",
      " [0.14947279]\n",
      " [0.01180483]\n",
      " [0.06870184]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.11589418]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.08570642]\n",
      " [0.06870184]\n",
      " [0.10131262]\n",
      " [0.08716822]\n",
      " [0.08716822]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.08716822]\n",
      " [0.11589418]\n",
      " [0.11757129]\n",
      " [0.11757129]\n",
      " [0.11810686]\n",
      " [0.10131262]\n",
      " [0.10521755]\n",
      " [0.07781746]\n",
      " [0.19850859]\n",
      " [0.06021292]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.08716822]\n",
      " [0.10521755]\n",
      " [0.14947279]\n",
      " [0.11810686]\n",
      " [0.10521755]\n",
      " [0.09791354]\n",
      " [0.11810686]\n",
      " [0.06870184]\n",
      " [0.06696659]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.11589418]\n",
      " [0.10131262]\n",
      " [0.09141472]\n",
      " [0.10521755]\n",
      " [0.11810686]\n",
      " [0.11810686]\n",
      " [0.14491954]\n",
      " [0.06021292]\n",
      " [0.06696659]\n",
      " [0.06870184]\n",
      " [0.11810686]\n",
      " [0.23520137]\n",
      " [0.11589418]]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14947279]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plswork():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    NLPdata = pd.read_csv('nlpdata.csv')\n",
    "    NLPdata = NLPdata.to_numpy()\n",
    "    model = load_model('my_model.h5')\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0:2], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "    X_train = X_train.reshape(-1,2)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    X_test = X_test.reshape(-1,2)\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run through 1\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 62/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 69/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 76/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 143/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 150/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 157/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 224/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 231/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 238/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Run through 2\n",
      "Epoch 1/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 2/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 3/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 4/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 5/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 6/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 7/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 8/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 9/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 10/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 11/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 12/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 13/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 14/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 15/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 16/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 17/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 18/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 19/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 20/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 21/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 22/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 23/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 24/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 25/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 26/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 27/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 28/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 29/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 30/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 31/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 32/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 33/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 34/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 35/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 36/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 37/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 38/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 39/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 40/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 41/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 42/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 43/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 44/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 45/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 46/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 47/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 48/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 49/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 50/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 51/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 52/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 53/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 54/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 55/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 56/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 57/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 58/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 59/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 60/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 61/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 62/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 63/250\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 64/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 65/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 66/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 67/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 68/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 69/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 70/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 71/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 72/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 73/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 74/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 75/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 76/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 77/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 78/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 79/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 80/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 81/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 82/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 83/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 84/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 85/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 86/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 87/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 88/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 89/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 90/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 91/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 92/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 93/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 94/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 95/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 96/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 97/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 98/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 99/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 100/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 101/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 102/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 103/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 104/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 105/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 106/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 107/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 108/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 109/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 110/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 111/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 112/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 113/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 114/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 115/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 116/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 117/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 118/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 119/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 120/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 121/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 122/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 123/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 124/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 125/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 126/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 127/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 128/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 129/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 130/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 131/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 132/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 133/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 134/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 135/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 136/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 137/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 138/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 139/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 140/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 141/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 142/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 143/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 144/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 145/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 146/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 147/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 148/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 149/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 150/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 151/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 152/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 153/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 154/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 155/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 156/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 157/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 158/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 159/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 160/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 161/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 162/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 163/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 164/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 165/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 166/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 167/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 168/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 169/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 170/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 171/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 172/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 173/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 174/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 175/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 176/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 177/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 178/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 179/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 180/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 181/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 182/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 183/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 184/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 185/250\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 186/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 187/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 188/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 189/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 190/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 191/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 192/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 193/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 194/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 195/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 196/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 197/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 198/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 199/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 200/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 201/250\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 202/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 203/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 204/250\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 205/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 206/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 207/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 208/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 209/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 210/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 211/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 212/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 213/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 214/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 215/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 216/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 217/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 218/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 219/250\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 220/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 221/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 222/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 223/250\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 224/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 225/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 226/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 227/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 228/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 229/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 230/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 231/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 232/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 233/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 234/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 235/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 236/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 237/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 239/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 240/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 241/250\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 242/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 243/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 244/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 245/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 246/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 247/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 248/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 249/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 250/250\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print('Run through', +i+1)\n",
    "    plswork()\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=250, verbose=1, validation_data=(X_test, y_test))\n",
    "    model.evaluate(X_test, y_test)\n",
    "    X_new = X_test\n",
    "    y_proba = model.predict(X_new)\n",
    "    predict = np.vstack(y_proba)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.hist(y_proba, bins=20, histtype='step')\n",
    "    plt.savefig('hists4[i].png')            \n",
    "    #correlation = stats.pearsonr(y_proba.flatten(), y_test.flatten())[0]\n",
    "    #print(y_proba)\n",
    "    #predict = y_proba    \n",
    "    predictions = np.hstack(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92,)\n",
      "(92, 1)\n",
      "(92, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "print(y_proba.shape)\n",
    "print(predict.shape)\n",
    "\n",
    "print(type(predictions))\n",
    "print(type(y_proba))\n",
    "print(type(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "predict = y_proba    \n",
    "predictions = np.vstack(predict)\n",
    "\n",
    "print(predictions.shape)\n",
    "print(type(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05559748],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.14240076],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.08595385],\n",
       "       [0.07652082],\n",
       "       [0.09778327],\n",
       "       [0.05942924],\n",
       "       [0.10364183],\n",
       "       [0.1604441 ],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08686834],\n",
       "       [0.08686834],\n",
       "       [0.08595385],\n",
       "       [0.19857706],\n",
       "       [0.23151669],\n",
       "       [0.08686834],\n",
       "       [0.09778327],\n",
       "       [0.11557952],\n",
       "       [0.11557952],\n",
       "       [0.08686834],\n",
       "       [0.19857706],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.08595381],\n",
       "       [0.08689348],\n",
       "       [0.09778327],\n",
       "       [0.05559748],\n",
       "       [0.06202861],\n",
       "       [0.04666788],\n",
       "       [0.0657547 ],\n",
       "       [0.06202861],\n",
       "       [0.08595385],\n",
       "       [0.14240076],\n",
       "       [0.01414515],\n",
       "       [0.0657547 ],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.11578416],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.0868932 ],\n",
       "       [0.0657547 ],\n",
       "       [0.09778327],\n",
       "       [0.08686834],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08686834],\n",
       "       [0.11578416],\n",
       "       [0.11557952],\n",
       "       [0.11557952],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.07652114],\n",
       "       [0.19857726],\n",
       "       [0.05559748],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.08686834],\n",
       "       [0.10364183],\n",
       "       [0.14240076],\n",
       "       [0.11588249],\n",
       "       [0.10364183],\n",
       "       [0.09606189],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.05985299],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.11578416],\n",
       "       [0.09778327],\n",
       "       [0.0930132 ],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.14098944],\n",
       "       [0.05559748],\n",
       "       [0.05985299],\n",
       "       [0.0657547 ],\n",
       "       [0.11588249],\n",
       "       [0.23121367],\n",
       "       [0.11578416]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey = model.predict(X_new)\n",
    "hey.shape\n",
    "type(hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ho = model.predict(X_train)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "letsgo = np.append([hey],[ho])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(letsgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letsgo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05559748],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.14240076],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.08595385],\n",
       "       [0.07652082],\n",
       "       [0.09778327],\n",
       "       [0.05942924],\n",
       "       [0.10364183],\n",
       "       [0.1604441 ],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08686834],\n",
       "       [0.08686834],\n",
       "       [0.08595385],\n",
       "       [0.19857706],\n",
       "       [0.23151669],\n",
       "       [0.08686834],\n",
       "       [0.09778327],\n",
       "       [0.11557952],\n",
       "       [0.11557952],\n",
       "       [0.08686834],\n",
       "       [0.19857706],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.08595381],\n",
       "       [0.08689348],\n",
       "       [0.09778327],\n",
       "       [0.05559748],\n",
       "       [0.06202861],\n",
       "       [0.04666788],\n",
       "       [0.0657547 ],\n",
       "       [0.06202861],\n",
       "       [0.08595385],\n",
       "       [0.14240076],\n",
       "       [0.01414515],\n",
       "       [0.0657547 ],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.11578416],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.0868932 ],\n",
       "       [0.0657547 ],\n",
       "       [0.09778327],\n",
       "       [0.08686834],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08686834],\n",
       "       [0.11578416],\n",
       "       [0.11557952],\n",
       "       [0.11557952],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.07652114],\n",
       "       [0.19857726],\n",
       "       [0.05559748],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.08686834],\n",
       "       [0.10364183],\n",
       "       [0.14240076],\n",
       "       [0.11588249],\n",
       "       [0.10364183],\n",
       "       [0.09606189],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.05985299],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.11578416],\n",
       "       [0.09778327],\n",
       "       [0.0930132 ],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.14098944],\n",
       "       [0.05559748],\n",
       "       [0.05985299],\n",
       "       [0.0657547 ],\n",
       "       [0.11588249],\n",
       "       [0.23121367],\n",
       "       [0.11578416],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.08832066],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.11578416],\n",
       "       [0.07652082],\n",
       "       [0.06202861],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.08686834],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08595385],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.10364183],\n",
       "       [0.01414515],\n",
       "       [0.08595385],\n",
       "       [0.07652082],\n",
       "       [0.06202861],\n",
       "       [0.11588249],\n",
       "       [0.11557952],\n",
       "       [0.20487772],\n",
       "       [0.11588267],\n",
       "       [0.11588249],\n",
       "       [0.01414515],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.01414515],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.05942924],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.05985299],\n",
       "       [0.14098944],\n",
       "       [0.05942924],\n",
       "       [0.0657547 ],\n",
       "       [0.1604441 ],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.08595385],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.01414515],\n",
       "       [0.23121367],\n",
       "       [0.11588249],\n",
       "       [0.08686834],\n",
       "       [0.08595385],\n",
       "       [0.09778327],\n",
       "       [0.14240076],\n",
       "       [0.05559748],\n",
       "       [0.08595381],\n",
       "       [0.0977833 ],\n",
       "       [0.11578416],\n",
       "       [0.11588249],\n",
       "       [0.11557952],\n",
       "       [0.09778327],\n",
       "       [0.11557952],\n",
       "       [0.10364183],\n",
       "       [0.2048776 ],\n",
       "       [0.10825957],\n",
       "       [0.07563194],\n",
       "       [0.11588249],\n",
       "       [0.05559748],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.1604441 ],\n",
       "       [0.0657547 ],\n",
       "       [0.06202861],\n",
       "       [0.11588249],\n",
       "       [0.06202861],\n",
       "       [0.11588249],\n",
       "       [0.07563194],\n",
       "       [0.09778327],\n",
       "       [0.06202861],\n",
       "       [0.08686834],\n",
       "       [0.19857706],\n",
       "       [0.10364183],\n",
       "       [0.01414515],\n",
       "       [0.10364183],\n",
       "       [0.10364183],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.0977833 ],\n",
       "       [0.14098929],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.07563194],\n",
       "       [0.0868932 ],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.08595385],\n",
       "       [0.08595385],\n",
       "       [0.09778327],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.11578416],\n",
       "       [0.06202861],\n",
       "       [0.08595385],\n",
       "       [0.10825957],\n",
       "       [0.04666788],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.01414515],\n",
       "       [0.11588249],\n",
       "       [0.08832066],\n",
       "       [0.06202861],\n",
       "       [0.14098944],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.08595385],\n",
       "       [0.11588267],\n",
       "       [0.10364226],\n",
       "       [0.0657547 ],\n",
       "       [0.11588249],\n",
       "       [0.10364183],\n",
       "       [0.05559748],\n",
       "       [0.11588249],\n",
       "       [0.06202861],\n",
       "       [0.07563194],\n",
       "       [0.11616593],\n",
       "       [0.07563194],\n",
       "       [0.0657547 ],\n",
       "       [0.05559748],\n",
       "       [0.14098944],\n",
       "       [0.11588249],\n",
       "       [0.11578416],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.05559748],\n",
       "       [0.01414515],\n",
       "       [0.11578416],\n",
       "       [0.10364183],\n",
       "       [0.0657547 ],\n",
       "       [0.08595385],\n",
       "       [0.11588249],\n",
       "       [0.00813413],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.0868932 ],\n",
       "       [0.04666788],\n",
       "       [0.11588249],\n",
       "       [0.11578421],\n",
       "       [0.05559753],\n",
       "       [0.11588249],\n",
       "       [0.01414515],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.10364183],\n",
       "       [0.0868932 ],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.23151669],\n",
       "       [0.14240076],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.05559748],\n",
       "       [0.08686834],\n",
       "       [0.10364183],\n",
       "       [0.09778327],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.08595385],\n",
       "       [0.11588249],\n",
       "       [0.11557952],\n",
       "       [0.0905693 ],\n",
       "       [0.05985299],\n",
       "       [0.0657547 ],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.00813413],\n",
       "       [0.08595385],\n",
       "       [0.08686834],\n",
       "       [0.05942921],\n",
       "       [0.08686808],\n",
       "       [0.09778327],\n",
       "       [0.11578416],\n",
       "       [0.1604441 ],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.10364183],\n",
       "       [0.01414515],\n",
       "       [0.09778327],\n",
       "       [0.07652082],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.05559748],\n",
       "       [0.08595385],\n",
       "       [0.11578416],\n",
       "       [0.19857706],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.08595385],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.0868932 ],\n",
       "       [0.11588249],\n",
       "       [0.08595385],\n",
       "       [0.08595385],\n",
       "       [0.0868932 ],\n",
       "       [0.0657547 ],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588267],\n",
       "       [0.16044389],\n",
       "       [0.09778327],\n",
       "       [0.06864575],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.05559748],\n",
       "       [0.14240076],\n",
       "       [0.06202861],\n",
       "       [0.10825957],\n",
       "       [0.11578416],\n",
       "       [0.09778327],\n",
       "       [0.05559748],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.0868932 ],\n",
       "       [0.11588249],\n",
       "       [0.11588249],\n",
       "       [0.0868932 ],\n",
       "       [0.08686834],\n",
       "       [0.11578416],\n",
       "       [0.23121367],\n",
       "       [0.08686834],\n",
       "       [0.09778327],\n",
       "       [0.10364183],\n",
       "       [0.06202861],\n",
       "       [0.05559748],\n",
       "       [0.0977833 ],\n",
       "       [0.0977833 ],\n",
       "       [0.11588249],\n",
       "       [0.11578416],\n",
       "       [0.08686834],\n",
       "       [0.11588249],\n",
       "       [0.08595385],\n",
       "       [0.09778327],\n",
       "       [0.0657547 ],\n",
       "       [0.05559748],\n",
       "       [0.10364183],\n",
       "       [0.11588249],\n",
       "       [0.0657547 ],\n",
       "       [0.11557952],\n",
       "       [0.09778327],\n",
       "       [0.11588249],\n",
       "       [0.11578416],\n",
       "       [0.11588249],\n",
       "       [0.01414515]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letsgo.reshape(365,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letsgo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05906188 0.10647549 0.1012534  0.14606068 0.1012534  0.10647549\n",
      " 0.1012534  0.08843252 0.07944579 0.1012534  0.06232237 0.10647549\n",
      " 0.16392347 0.1012534  0.1012534  0.11898061 0.11898061 0.08983203\n",
      " 0.08983203 0.08843252 0.19962734 0.2342988  0.08983203 0.1012534\n",
      " 0.11925132 0.11925132 0.08983203 0.19962734 0.11898061 0.06859992\n",
      " 0.08843289 0.08965418 0.1012534  0.05906188 0.06390443 0.05026627\n",
      " 0.06859992 0.06390443 0.08843252 0.14606068 0.01600293 0.06859992\n",
      " 0.10647549 0.11898061 0.1012534  0.1193398  0.11898061 0.1012534\n",
      " 0.08965421 0.06859992 0.1012534  0.08983203 0.08983203 0.11898061\n",
      " 0.11898061 0.08983203 0.1193398  0.11925132 0.11925132 0.11898061\n",
      " 0.1012534  0.10647549 0.07944549 0.19962728 0.05906188 0.11898061\n",
      " 0.11898061 0.06859992 0.08983203 0.10647549 0.14606068 0.11898061\n",
      " 0.10647549 0.09984552 0.11898061 0.06859992 0.06298661 0.10647549\n",
      " 0.11898061 0.1193398  0.1012534  0.09575716 0.10647549 0.11898061\n",
      " 0.11898061 0.14468616 0.05906188 0.06298661 0.06859992 0.11898061\n",
      " 0.23288524 0.1193398 ]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "one = np.array([1])\n",
    "print(one)\n",
    "two = np.array([2])\n",
    "print(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three = np.hstack(([one],[two]))\n",
    "print(three)\n",
    "three.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 92)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = np.array(np.zeros(([1, 92]), dtype = int))\n",
    "print(four)\n",
    "four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = four.T\n",
    "print(four)\n",
    "four.shape\n",
    "#five = np.append(four, y_proba)\n",
    "#print(five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Input array : \n",
      " [[ 1  2  3]\n",
      " [-1 -2 -3]]\n",
      "2nd Input array : \n",
      " [[ 4  5  6]\n",
      " [-4 -5 -6]]\n",
      "Output stacked array :\n",
      "  [[ 1  2  3  4  5  6]\n",
      " [-1 -2 -3 -4 -5 -6]]\n"
     ]
    }
   ],
   "source": [
    "# example from https://www.geeksforgeeks.org/numpy-hstack-in-python/\n",
    "\n",
    "# input array \n",
    "in_arr1 = np.array([[ 1, 2, 3], [ -1, -2, -3]] ) \n",
    "print (\"1st Input array : \\n\", in_arr1)  \n",
    "  \n",
    "in_arr2 = np.array([[ 4, 5, 6], [ -4, -5, -6]] ) \n",
    "print (\"2nd Input array : \\n\", in_arr2)  \n",
    "  \n",
    "# Stacking the two arrays horizontally \n",
    "out_arr = np.hstack((in_arr1, in_arr2)) \n",
    "print (\"Output stacked array :\\n \", out_arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
