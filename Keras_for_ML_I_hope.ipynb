{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc4\n",
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPdata = pd.read_csv('nlpdata.csv')\n",
    "NLPdata = NLPdata.to_numpy()\n",
    "#X1train = NLParray[:,0].reshape((-1,1))\n",
    "#X2train = NLParray[:,1].reshape((-1,1))\n",
    "#Ytrain = NLParray[:,2]\n",
    "#print(X1train)\n",
    "#print(X2train)\n",
    "#print(Ytrain)\n",
    "\n",
    "#NLPdata = pd.read_csv('nlpdata.csv')\n",
    "#NLPdata = NLPdata.to_numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Original testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=1)) \n",
    "model.add(Dense(28, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [4. 4. 5. 4. 4. 4. 4. 4. 3. 1. 4. 4. 3. 4. 4. 4. 4. 4. 4. 2. 4. 4. 4. 3.\n",
      " 1. 2. 3. 1. 4. 4. 6. 4. 4. 1. 4. 4. 1. 4. 4. 2. 3. 4. 4. 2. 1. 5. 3. 2.\n",
      " 5. 4. 4. 2. 4. 4. 1. 1. 4. 4. 2. 4. 2. 3. 2. 4. 4. 4. 4. 4. 4. 3. 6. 3.\n",
      " 3. 4. 3. 4. 2. 5. 2. 1. 4. 1. 4. 3. 4. 1. 4. 1. 3. 1. 3. 3. 3. 4. 4. 5.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 4. 4. 1. 2. 3. 2. 4. 4. 4. 1. 4.\n",
      " 5. 1. 5. 4. 4. 2. 4. 3. 2. 4. 3. 3. 4. 1. 3. 5. 3. 2. 3. 5. 4. 4. 4. 4.\n",
      " 3. 1. 4. 3. 2. 2. 4. 2. 4. 4. 4. 4. 2. 4. 4. 3. 4. 1. 4. 4. 4. 3. 4. 4.\n",
      " 2. 2. 2. 4. 4. 3. 4. 3. 4. 4. 2. 2. 4. 4. 5. 1. 2. 4. 4. 2. 2. 4. 3. 4.\n",
      " 4. 4. 5. 4. 2. 3. 1. 4. 3. 4. 4. 3. 2. 4. 1. 4. 4. 2. 4. 4. 4. 4. 4. 4.\n",
      " 2. 2. 4. 2. 4. 4. 4. 5. 4. 3. 4. 4. 3. 2. 1. 3. 4. 4. 3. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 3. 1. 3. 4. 4. 4. 4. 4. 4. 2. 4. 2. 3.\n",
      " 3. 4. 2. 4. 4. 4. 4. 4. 1.]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [3. 3. 4. 2. 4. 3. 4. 2. 3. 4. 3. 3. 5. 4. 4. 4. 4. 4. 4. 2. 1. 2. 4. 4.\n",
      " 4. 4. 4. 1. 4. 2. 2. 4. 4. 3. 1. 2. 2. 1. 2. 2. 1. 2. 3. 4. 4. 4. 4. 4.\n",
      " 4. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 3. 1. 3. 4. 4. 2. 4. 3. 2. 4.\n",
      " 3. 5. 4. 2. 1. 3. 4. 4. 4. 4. 3. 4. 4. 5. 3. 1. 2. 4. 1. 4.]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0408 - val_loss: 0.0431\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.0429\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ff0a4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=30, epochs=20, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-0dcca7972e3a>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 7, 3, 7, 3, 7, 3, 7, 7, 3, 7, 7, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7,\n",
       "       3, 3, 3, 3, 3, 7, 3, 7, 7, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3,\n",
       "       3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 3,\n",
       "       3, 7, 3, 7, 7, 3, 7, 3, 3, 7, 7, 7, 3, 3, 3, 3, 7, 3, 3, 3, 7, 7,\n",
       "       7, 3, 7, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=30)\n",
    "model.predict_classes(X_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 7, 1, 7, 1, 6, 7, 1, 7, 2, 7, 1, 7, 6, 7, 7, 7, 7, 6, 7, 1,\n",
       "       7, 6, 7, 7, 7, 2, 7, 7, 1, 7, 7, 7, 1, 1, 7, 7, 7, 2, 7, 6, 7, 6,\n",
       "       7, 6, 1, 2, 7, 1, 6, 7, 1, 6, 2, 2, 6, 7, 7, 7, 2, 2, 7, 7, 7, 7,\n",
       "       7, 7, 7, 2, 1, 6, 1, 6, 7, 1, 6, 2, 7, 1, 6, 2, 2, 1, 1, 6, 6, 2,\n",
       "       1, 2, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test\n",
    "y_proba = model.predict(X_new).round(2) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "# now let's try a prediction based on Q40\n",
    "\n",
    "X_train2, X_test2, y_train, y_test = model_selection.train_test_split(NLPdata[:,1], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train2 = X_train2.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test2 = X_test2.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train2: \", X_train2)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test2: \", X_test2)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140650c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train, batch_size=30, epochs=20, verbose=1, validation_data=(X_test2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test2, y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, 5, 1, 4, 1, 4, 5, 1, 1, 4, 4, 1, 1, 4, 4, 1, 1, 4, 5, 4,\n",
       "       1, 1, 4, 4, 1, 5, 4, 1, 4, 5, 1, 1, 1, 1, 1, 1, 4, 5, 4, 1, 4, 4,\n",
       "       1, 5, 4, 1, 5, 1, 1, 1, 1, 4, 4, 1, 5, 4, 4, 4, 1, 4, 5, 5, 1, 4,\n",
       "       4, 1, 1, 4, 5, 4, 4, 4, 4, 1, 1, 4, 4, 5, 1, 5, 4, 4, 4, 1, 1, 1,\n",
       "       1, 4, 4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test2, batch_size=30)\n",
    "model.predict_classes(X_test2, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, 8, 1, 8, 5, 1, 8, 1, 2, 1, 8, 1, 6, 1, 1, 1, 1, 5, 1, 8,\n",
       "       1, 6, 1, 1, 1, 5, 1, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 4, 1, 6, 1, 6,\n",
       "       1, 6, 5, 8, 1, 8, 6, 1, 8, 6, 4, 4, 5, 1, 1, 1, 8, 4, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 8, 6, 8, 6, 1, 8, 6, 4, 1, 8, 6, 5, 5, 1, 8, 5, 5, 8,\n",
       "       8, 5, 4, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09998539 0.10000912 0.10010646 0.09991924 0.09977337 0.10015895\n",
      "  0.10014445 0.09998294 0.09981182 0.10010825]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09998539 0.10000912 0.10010646 0.09991924 0.09977337 0.10015895\n",
      "  0.10014444 0.09998294 0.09981181 0.10010826]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006045 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986447 0.09993964 0.10009894]\n",
      " [0.09994822 0.09962972 0.10006045 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986447 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994856 0.09980997 0.1001035  0.10002925 0.09982955 0.10020814\n",
      "  0.10017777 0.09993008 0.09984594 0.1001172 ]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing round 2,  12/28/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPdata = pd.read_csv('nlpdata.csv')\n",
    "NLPdata = NLPdata.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=1)) \n",
    "#model.add(Dense(28, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [4. 4. 5. 4. 4. 4. 4. 4. 3. 1. 4. 4. 3. 4. 4. 4. 4. 4. 4. 2. 4. 4. 4. 3.\n",
      " 1. 2. 3. 1. 4. 4. 6. 4. 4. 1. 4. 4. 1. 4. 4. 2. 3. 4. 4. 2. 1. 5. 3. 2.\n",
      " 5. 4. 4. 2. 4. 4. 1. 1. 4. 4. 2. 4. 2. 3. 2. 4. 4. 4. 4. 4. 4. 3. 6. 3.\n",
      " 3. 4. 3. 4. 2. 5. 2. 1. 4. 1. 4. 3. 4. 1. 4. 1. 3. 1. 3. 3. 3. 4. 4. 5.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 4. 4. 1. 2. 3. 2. 4. 4. 4. 1. 4.\n",
      " 5. 1. 5. 4. 4. 2. 4. 3. 2. 4. 3. 3. 4. 1. 3. 5. 3. 2. 3. 5. 4. 4. 4. 4.\n",
      " 3. 1. 4. 3. 2. 2. 4. 2. 4. 4. 4. 4. 2. 4. 4. 3. 4. 1. 4. 4. 4. 3. 4. 4.\n",
      " 2. 2. 2. 4. 4. 3. 4. 3. 4. 4. 2. 2. 4. 4. 5. 1. 2. 4. 4. 2. 2. 4. 3. 4.\n",
      " 4. 4. 5. 4. 2. 3. 1. 4. 3. 4. 4. 3. 2. 4. 1. 4. 4. 2. 4. 4. 4. 4. 4. 4.\n",
      " 2. 2. 4. 2. 4. 4. 4. 5. 4. 3. 4. 4. 3. 2. 1. 3. 4. 4. 3. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 3. 1. 3. 4. 4. 4. 4. 4. 4. 2. 4. 2. 3.\n",
      " 3. 4. 2. 4. 4. 4. 4. 4. 1.]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [3. 3. 4. 2. 4. 3. 4. 2. 3. 4. 3. 3. 5. 4. 4. 4. 4. 4. 4. 2. 1. 2. 4. 4.\n",
      " 4. 4. 4. 1. 4. 2. 2. 4. 4. 3. 1. 2. 2. 1. 2. 2. 1. 2. 3. 4. 4. 4. 4. 4.\n",
      " 4. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 3. 1. 3. 4. 4. 2. 4. 3. 2. 4.\n",
      " 3. 5. 4. 2. 1. 3. 4. 4. 4. 4. 3. 4. 4. 5. 3. 1. 2. 4. 1. 4.]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0450\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0432\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0430\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0429\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0428\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1406a8400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04280076175928116"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) #, batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 7, 4, 7, 4, 7, 4, 4, 7, 4, 4, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4,\n",
       "       7, 7, 7, 7, 7, 4, 7, 4, 4, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7,\n",
       "       7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4, 4, 7,\n",
       "       7, 4, 7, 4, 4, 7, 4, 7, 7, 4, 4, 4, 7, 7, 7, 7, 4, 7, 7, 7, 4, 4,\n",
       "       4, 7, 4, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=30)\n",
    "model.predict_classes(X_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 9, 9, 4, 9, 9, 9, 9, 4, 9, 4, 9, 9, 5, 9, 9, 4, 4, 9, 4, 9,\n",
       "       4, 5, 4, 4, 9, 9, 9, 4, 9, 4, 9, 9, 9, 9, 4, 9, 9, 9, 4, 5, 4, 5,\n",
       "       4, 5, 9, 9, 4, 9, 5, 4, 9, 5, 9, 9, 9, 4, 4, 9, 9, 9, 9, 4, 9, 4,\n",
       "       9, 4, 4, 9, 9, 5, 9, 5, 4, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253247\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949061 0.09992879 0.10024744 0.09887736 0.09886298\n",
      "  0.09964871 0.10390862 0.10080178 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081189 0.09958656 0.09935688 0.10159941 0.10071494\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623281 0.09240184 0.10687736]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "# now let's try a prediction based on Q40\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = model_selection.train_test_split(NLPdata[:,1], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14092f280>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, batch_size=10, epochs=10, verbose=1, validation_data=(X_test2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04280411824584007"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2, y_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 4, 7, 4, 9, 4, 9, 7, 4, 4, 9, 9, 4, 4, 9, 9, 4, 4, 9, 7, 7,\n",
       "       4, 4, 7, 7, 4, 7, 9, 4, 9, 1, 4, 4, 4, 4, 4, 4, 9, 7, 9, 4, 9, 9,\n",
       "       4, 7, 9, 4, 1, 4, 4, 4, 4, 9, 9, 4, 7, 7, 7, 9, 4, 9, 7, 7, 4, 9,\n",
       "       9, 4, 4, 9, 7, 9, 9, 7, 9, 4, 4, 9, 9, 7, 4, 7, 9, 9, 9, 4, 4, 4,\n",
       "       4, 9, 7, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test2, batch_size=10)\n",
    "model.predict_classes(X_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 9, 9, 4, 9, 5, 9, 9, 4, 9, 4, 9, 4, 2, 4, 9, 4, 4, 9, 4, 9,\n",
       "       4, 2, 4, 4, 9, 9, 4, 4, 9, 4, 9, 4, 9, 9, 4, 4, 9, 9, 4, 5, 4, 5,\n",
       "       4, 2, 9, 9, 4, 9, 5, 4, 9, 5, 9, 9, 5, 4, 4, 9, 9, 9, 4, 4, 4, 4,\n",
       "       4, 4, 4, 9, 9, 2, 9, 2, 4, 9, 5, 9, 4, 9, 5, 9, 9, 9, 9, 5, 5, 9,\n",
       "       9, 9, 9, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test2, batch_size=10)\n",
    "model.predict_classes(y_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10038743 0.1005327  0.10005388 0.10029481 0.10021456 0.09993967\n",
      "  0.10001431 0.09881385 0.10000346 0.09974536]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10038742 0.1005327  0.10005388 0.1002948  0.10021456 0.09993968\n",
      "  0.10001431 0.09881384 0.10000346 0.09974536]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033736 0.09750504 0.09817898\n",
      "  0.09923382 0.10880695 0.10137435 0.09699066]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033736 0.09750504 0.09817898\n",
      "  0.09923382 0.10880695 0.10137435 0.09699066]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09968793 0.09956505 0.10005908 0.10033149 0.0988657  0.09907065\n",
      "  0.0996386  0.10370601 0.10070203 0.0983735 ]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new).round(2)\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
