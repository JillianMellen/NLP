{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc4\n",
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPdata = pd.read_csv('nlpdata.csv')\n",
    "NLPdata = NLPdata.to_numpy()\n",
    "#X1train = NLParray[:,0].reshape((-1,1))\n",
    "#X2train = NLParray[:,1].reshape((-1,1))\n",
    "#Ytrain = NLParray[:,2]\n",
    "#print(X1train)\n",
    "#print(X2train)\n",
    "#print(Ytrain)\n",
    "\n",
    "#NLPdata = pd.read_csv('nlpdata.csv')\n",
    "#NLPdata = NLPdata.to_numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Original testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=1)) \n",
    "model.add(Dense(28, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [4. 4. 5. 4. 4. 4. 4. 4. 3. 1. 4. 4. 3. 4. 4. 4. 4. 4. 4. 2. 4. 4. 4. 3.\n",
      " 1. 2. 3. 1. 4. 4. 6. 4. 4. 1. 4. 4. 1. 4. 4. 2. 3. 4. 4. 2. 1. 5. 3. 2.\n",
      " 5. 4. 4. 2. 4. 4. 1. 1. 4. 4. 2. 4. 2. 3. 2. 4. 4. 4. 4. 4. 4. 3. 6. 3.\n",
      " 3. 4. 3. 4. 2. 5. 2. 1. 4. 1. 4. 3. 4. 1. 4. 1. 3. 1. 3. 3. 3. 4. 4. 5.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 4. 4. 1. 2. 3. 2. 4. 4. 4. 1. 4.\n",
      " 5. 1. 5. 4. 4. 2. 4. 3. 2. 4. 3. 3. 4. 1. 3. 5. 3. 2. 3. 5. 4. 4. 4. 4.\n",
      " 3. 1. 4. 3. 2. 2. 4. 2. 4. 4. 4. 4. 2. 4. 4. 3. 4. 1. 4. 4. 4. 3. 4. 4.\n",
      " 2. 2. 2. 4. 4. 3. 4. 3. 4. 4. 2. 2. 4. 4. 5. 1. 2. 4. 4. 2. 2. 4. 3. 4.\n",
      " 4. 4. 5. 4. 2. 3. 1. 4. 3. 4. 4. 3. 2. 4. 1. 4. 4. 2. 4. 4. 4. 4. 4. 4.\n",
      " 2. 2. 4. 2. 4. 4. 4. 5. 4. 3. 4. 4. 3. 2. 1. 3. 4. 4. 3. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 3. 1. 3. 4. 4. 4. 4. 4. 4. 2. 4. 2. 3.\n",
      " 3. 4. 2. 4. 4. 4. 4. 4. 1.]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [3. 3. 4. 2. 4. 3. 4. 2. 3. 4. 3. 3. 5. 4. 4. 4. 4. 4. 4. 2. 1. 2. 4. 4.\n",
      " 4. 4. 4. 1. 4. 2. 2. 4. 4. 3. 1. 2. 2. 1. 2. 2. 1. 2. 3. 4. 4. 4. 4. 4.\n",
      " 4. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 3. 1. 3. 4. 4. 2. 4. 3. 2. 4.\n",
      " 3. 5. 4. 2. 1. 3. 4. 4. 4. 4. 3. 4. 4. 5. 3. 1. 2. 4. 1. 4.]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0408 - val_loss: 0.0431\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.0429\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ff0a4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=30, epochs=20, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-0dcca7972e3a>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 7, 3, 7, 3, 7, 3, 7, 7, 3, 7, 7, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7,\n",
       "       3, 3, 3, 3, 3, 7, 3, 7, 7, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3,\n",
       "       3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 3,\n",
       "       3, 7, 3, 7, 7, 3, 7, 3, 3, 7, 7, 7, 3, 3, 3, 3, 7, 3, 3, 3, 7, 7,\n",
       "       7, 3, 7, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=30)\n",
    "model.predict_classes(X_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 7, 1, 7, 1, 6, 7, 1, 7, 2, 7, 1, 7, 6, 7, 7, 7, 7, 6, 7, 1,\n",
       "       7, 6, 7, 7, 7, 2, 7, 7, 1, 7, 7, 7, 1, 1, 7, 7, 7, 2, 7, 6, 7, 6,\n",
       "       7, 6, 1, 2, 7, 1, 6, 7, 1, 6, 2, 2, 6, 7, 7, 7, 2, 2, 7, 7, 7, 7,\n",
       "       7, 7, 7, 2, 1, 6, 1, 6, 7, 1, 6, 2, 7, 1, 6, 2, 2, 1, 1, 6, 6, 2,\n",
       "       1, 2, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test\n",
    "y_proba = model.predict(X_new).round(2) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "# now let's try a prediction based on Q40\n",
    "\n",
    "X_train2, X_test2, y_train, y_test = model_selection.train_test_split(NLPdata[:,1], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train2 = X_train2.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test2 = X_test2.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train2: \", X_train2)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test2: \", X_test2)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140650c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train, batch_size=30, epochs=20, verbose=1, validation_data=(X_test2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test2, y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, 5, 1, 4, 1, 4, 5, 1, 1, 4, 4, 1, 1, 4, 4, 1, 1, 4, 5, 4,\n",
       "       1, 1, 4, 4, 1, 5, 4, 1, 4, 5, 1, 1, 1, 1, 1, 1, 4, 5, 4, 1, 4, 4,\n",
       "       1, 5, 4, 1, 5, 1, 1, 1, 1, 4, 4, 1, 5, 4, 4, 4, 1, 4, 5, 5, 1, 4,\n",
       "       4, 1, 1, 4, 5, 4, 4, 4, 4, 1, 1, 4, 4, 5, 1, 5, 4, 4, 4, 1, 1, 1,\n",
       "       1, 4, 4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test2, batch_size=30)\n",
    "model.predict_classes(X_test2, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, 8, 1, 8, 5, 1, 8, 1, 2, 1, 8, 1, 6, 1, 1, 1, 1, 5, 1, 8,\n",
       "       1, 6, 1, 1, 1, 5, 1, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 4, 1, 6, 1, 6,\n",
       "       1, 6, 5, 8, 1, 8, 6, 1, 8, 6, 4, 4, 5, 1, 1, 1, 8, 4, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 8, 6, 8, 6, 1, 8, 6, 4, 1, 8, 6, 5, 5, 1, 8, 5, 5, 8,\n",
       "       8, 5, 4, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09998539 0.10000912 0.10010646 0.09991924 0.09977337 0.10015895\n",
      "  0.10014445 0.09998294 0.09981182 0.10010825]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09998539 0.10000912 0.10010646 0.09991924 0.09977337 0.10015895\n",
      "  0.10014444 0.09998294 0.09981181 0.10010826]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006045 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986447 0.09993964 0.10009894]\n",
      " [0.09994822 0.09962972 0.10006045 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986447 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994856 0.09980997 0.1001035  0.10002925 0.09982955 0.10020814\n",
      "  0.10017777 0.09993008 0.09984594 0.1001172 ]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.1000222  0.1002086  0.10010935 0.09980931 0.09971716 0.10010974\n",
      "  0.10011105 0.10003578 0.09977765 0.10009924]\n",
      " [0.09997921 0.10032825 0.10000892 0.0997367  0.09975554 0.10000326\n",
      "  0.10008276 0.10019363 0.09991469 0.09999702]\n",
      " [0.09994226 0.09995889 0.10003504 0.10007003 0.10007544 0.09998531\n",
      "  0.09989804 0.10002753 0.10005434 0.09995313]\n",
      " [0.10009629 0.09952457 0.09985424 0.10034314 0.10046484 0.09988546\n",
      "  0.0998387  0.09974682 0.10027613 0.09996981]\n",
      " [0.09994822 0.09962972 0.10006044 0.10015477 0.09997173 0.10018791\n",
      "  0.10014421 0.09986448 0.09993964 0.10009894]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing round 2,  12/28/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPdata = pd.read_csv('nlpdata.csv')\n",
    "NLPdata = NLPdata.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=1)) \n",
    "#model.add(Dense(28, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [4. 4. 5. 4. 4. 4. 4. 4. 3. 1. 4. 4. 3. 4. 4. 4. 4. 4. 4. 2. 4. 4. 4. 3.\n",
      " 1. 2. 3. 1. 4. 4. 6. 4. 4. 1. 4. 4. 1. 4. 4. 2. 3. 4. 4. 2. 1. 5. 3. 2.\n",
      " 5. 4. 4. 2. 4. 4. 1. 1. 4. 4. 2. 4. 2. 3. 2. 4. 4. 4. 4. 4. 4. 3. 6. 3.\n",
      " 3. 4. 3. 4. 2. 5. 2. 1. 4. 1. 4. 3. 4. 1. 4. 1. 3. 1. 3. 3. 3. 4. 4. 5.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 4. 4. 1. 2. 3. 2. 4. 4. 4. 1. 4.\n",
      " 5. 1. 5. 4. 4. 2. 4. 3. 2. 4. 3. 3. 4. 1. 3. 5. 3. 2. 3. 5. 4. 4. 4. 4.\n",
      " 3. 1. 4. 3. 2. 2. 4. 2. 4. 4. 4. 4. 2. 4. 4. 3. 4. 1. 4. 4. 4. 3. 4. 4.\n",
      " 2. 2. 2. 4. 4. 3. 4. 3. 4. 4. 2. 2. 4. 4. 5. 1. 2. 4. 4. 2. 2. 4. 3. 4.\n",
      " 4. 4. 5. 4. 2. 3. 1. 4. 3. 4. 4. 3. 2. 4. 1. 4. 4. 2. 4. 4. 4. 4. 4. 4.\n",
      " 2. 2. 4. 2. 4. 4. 4. 5. 4. 3. 4. 4. 3. 2. 1. 3. 4. 4. 3. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 3. 1. 3. 4. 4. 4. 4. 4. 4. 2. 4. 2. 3.\n",
      " 3. 4. 2. 4. 4. 4. 4. 4. 1.]\n",
      "y_train:  [ 0.05        0.15918367  0.          0.16241497  0.          0.15642857\n",
      " -0.09270833 -0.06452991  0.01012397  0.43333333 -0.02916667  0.109375\n",
      "  0.05333333  0.1        -0.01458333  0.0795068   0.09        0.17857143\n",
      "  0.275       0.06009091  0.2625     -0.01916667  0.09166667  0.27559524\n",
      "  0.13318182  0.5         0.19622024  0.          0.2         0.21785714\n",
      "  0.25       -0.10833333  0.15625     0.07666667  0.2625      0.22222222\n",
      "  0.0625     -0.08636364  0.18083333  0.          0.09970238  0.22166667\n",
      "  0.095       0.08848485  0.09333333  0.07238095 -0.175       0.03541667\n",
      "  0.17424242  0.11        0.09583333  0.16805556  0.06041667  0.19410173\n",
      "  0.          0.28541667  0.25        0.16369048  0.14166667  0.21875\n",
      "  0.2         0.18050964  0.29166667  0.         -0.02588745  0.23224638\n",
      "  0.          0.125       0.07935606  0.15        0.25        0.025\n",
      "  0.12       -0.078125   -0.071875   -0.08518518 -1.          0.14895833\n",
      "  0.01333333  0.2125      0.44        0.0125      0.06944444  0.12857143\n",
      "  0.04375     0.23459208  0.13928571  0.6         0.515      -0.13645833\n",
      "  0.25208333  0.28928571  0.13125     0.10476191  0.2         0.22857143\n",
      "  0.21808036  0.5         0.01882716  0.40333333  0.1         0.45833333\n",
      "  0.18095238  0.04791667  0.07058823  0.06924242  0.02222222  0.03629704\n",
      " -0.15555556 -0.05        0.23579545 -0.5         0.00449495  0.16666667\n",
      "  0.          0.13863636 -0.034375    0.         -0.66666667  0.14583333\n",
      "  0.10871212  0.15659341 -0.02630386 -0.00779221  0.6        -0.125\n",
      "  0.13333333  0.25        0.06966667  0.1         0.0375      0.00595238\n",
      "  0.01871693  0.10548611  0.259375    0.          0.2         0.11470058\n",
      "  0.06471861  0.1694697   0.20558036  0.52        0.06595238  0.075\n",
      "  0.22857143 -0.03333333  0.06666667 -0.01458333  0.1527972   0.11071429\n",
      "  0.          0.          0.05277778 -0.046875   -0.00333333  0.18229167\n",
      "  0.0476087   0.28214286  0.0875     -0.07777778  0.26944444  0.01\n",
      " -0.04466667  0.14404762  0.45        0.09761905  0.175      -0.03333333\n",
      "  0.45        0.06428571  0.1         0.20767196  0.          0.\n",
      "  0.26346154  0.14        0.45833333 -0.125       0.11583333  0.00476431\n",
      "  0.17777778  0.15833333 -0.14861111 -0.16666667  0.06944444  0.20857143\n",
      "  0.05404762 -0.04378157  0.15170068  0.125       0.08374242  0.16666667\n",
      "  0.          0.25        0.25909091  0.185       0.03592558  0.22777778\n",
      "  0.11308081  0.17291667 -0.25       -0.65       -0.11777778  0.02380952\n",
      "  0.          0.30833333 -0.015       0.09393939  0.0625      0.13809524\n",
      "  0.15333333 -0.04356061  0.09402597  0.2147549   0.3         0.20189349\n",
      "  0.28333333 -0.35       -0.1075      0.45        0.10555556  0.3\n",
      "  0.07052083  0.1225      0.17083333  0.2         0.06428571  0.02579365\n",
      " -1.          0.25        0.28583333  0.16176471  0.23333333  0.01369048\n",
      " -0.45        0.27575758  0.21666667  0.01111111  0.08416667 -0.01333333\n",
      "  0.19284512  0.16190476  0.01715007  0.01875     0.15        0.\n",
      "  0.04785902  0.20166667  0.17142857  0.28958333 -0.04523809 -0.01464646\n",
      "  0.0625      0.02166667  0.4        -0.03916667  0.5        -0.55\n",
      "  0.02060606  0.10833333  0.14526515  0.275       0.16666667  0.55\n",
      "  0.05552083 -0.06372549  0.          0.         -0.01277778  0.28888889\n",
      "  0.375      -0.31833333  0.46666667]\n",
      "X_test:  [3. 3. 4. 2. 4. 3. 4. 2. 3. 4. 3. 3. 5. 4. 4. 4. 4. 4. 4. 2. 1. 2. 4. 4.\n",
      " 4. 4. 4. 1. 4. 2. 2. 4. 4. 3. 1. 2. 2. 1. 2. 2. 1. 2. 3. 4. 4. 4. 4. 4.\n",
      " 4. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 3. 1. 3. 4. 4. 2. 4. 3. 2. 4.\n",
      " 3. 5. 4. 2. 1. 3. 4. 4. 4. 4. 3. 4. 4. 5. 3. 1. 2. 4. 1. 4.]\n",
      "y_test:  [ 0.275       0.00555556  0.13076923  0.10504329  0.25694444  0.09285714\n",
      " -0.04166667  0.125       0.09675698  0.5        -0.01186526  0.26666667\n",
      "  0.06435185  0.19027778 -0.4         0.18450635  0.15        0.24404762\n",
      "  0.34545455 -0.025       0.2125      0.1030303   0.44444444 -0.55555556\n",
      "  0.4         0.2765873   0.13026245  0.02453704  0.15948162  0.33888889\n",
      "  0.08458333  0.20160256  0.121875    0.19820513  0.06428571  0.09419643\n",
      "  0.19888889  0.1537037   0.15208333  0.          0.38333333 -0.2\n",
      "  0.28571429 -0.225       0.33333333 -0.29166667  0.05769231  0.01944444\n",
      "  0.675       0.09545455 -0.17638889  0.46666667  0.07967607 -0.2\n",
      "  0.          0.         -0.06527778  0.21645833  0.2575      0.12380952\n",
      "  0.01636905  0.          0.18333333  0.25        0.1625      0.56666667\n",
      "  0.155       0.44        0.3        -0.01214286  0.07142857 -0.3625\n",
      "  0.0625     -0.31666667  0.47916667  0.06666667 -0.20833333  0.\n",
      "  0.17381245  0.07795056 -0.14583333  0.03125     0.04494949  0.11909091\n",
      "  0.07944444 -0.0625     -0.1         0.01136364  0.10277778  0.02777778\n",
      "  0.          0.08863636]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(NLPdata[:,0], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0450\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0432\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0430\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0429\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0428\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1406a8400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04280076175928116"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) #, batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 7, 4, 7, 4, 7, 4, 4, 7, 4, 4, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4,\n",
       "       7, 7, 7, 7, 7, 4, 7, 4, 4, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7,\n",
       "       7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4, 4, 7,\n",
       "       7, 4, 7, 4, 4, 7, 4, 7, 7, 4, 4, 4, 7, 7, 7, 7, 4, 7, 7, 7, 4, 4,\n",
       "       4, 7, 4, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=30)\n",
    "model.predict_classes(X_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 9, 9, 4, 9, 9, 9, 9, 4, 9, 4, 9, 9, 5, 9, 9, 4, 4, 9, 4, 9,\n",
       "       4, 5, 4, 4, 9, 9, 9, 4, 9, 4, 9, 9, 9, 9, 4, 9, 9, 9, 4, 5, 4, 5,\n",
       "       4, 5, 9, 9, 4, 9, 5, 4, 9, 5, 9, 9, 9, 4, 4, 9, 9, 9, 9, 4, 9, 4,\n",
       "       9, 4, 4, 9, 9, 5, 9, 5, 4, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test, batch_size=30)\n",
    "model.predict_classes(y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253247\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949061 0.09992879 0.10024744 0.09887736 0.09886298\n",
      "  0.09964871 0.10390862 0.10080178 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10048839 0.10081189 0.09958656 0.09935688 0.10159941 0.10071494\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623281 0.09240184 0.10687736]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.09867053 0.09811851 0.10020258 0.10107579 0.09616145 0.09697772\n",
      "  0.09885885 0.1104214  0.103627   0.09588612]\n",
      " [0.10048839 0.10081188 0.09958655 0.09935687 0.10159941 0.10071493\n",
      "  0.10037519 0.09771206 0.09798554 0.10136919]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.10130636 0.10208189 0.09917866 0.0984079  0.10432606 0.10253246\n",
      "  0.10103885 0.09182316 0.09518383 0.10412084]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]\n",
      " [0.10206428 0.10330041 0.09870792 0.09740433 0.10705594 0.10431463\n",
      "  0.10164049 0.08623282 0.09240185 0.10687736]\n",
      " [0.09960989 0.09949062 0.09992879 0.10024745 0.09887737 0.09886299\n",
      "  0.09964871 0.10390861 0.10080179 0.09862378]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]]\n",
      "y_train:  [[ 0.05      ]\n",
      " [ 0.15918367]\n",
      " [ 0.        ]\n",
      " [ 0.16241497]\n",
      " [ 0.        ]\n",
      " [ 0.15642857]\n",
      " [-0.09270833]\n",
      " [-0.06452991]\n",
      " [ 0.01012397]\n",
      " [ 0.43333333]\n",
      " [-0.02916667]\n",
      " [ 0.109375  ]\n",
      " [ 0.05333333]\n",
      " [ 0.1       ]\n",
      " [-0.01458333]\n",
      " [ 0.0795068 ]\n",
      " [ 0.09      ]\n",
      " [ 0.17857143]\n",
      " [ 0.275     ]\n",
      " [ 0.06009091]\n",
      " [ 0.2625    ]\n",
      " [-0.01916667]\n",
      " [ 0.09166667]\n",
      " [ 0.27559524]\n",
      " [ 0.13318182]\n",
      " [ 0.5       ]\n",
      " [ 0.19622024]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.21785714]\n",
      " [ 0.25      ]\n",
      " [-0.10833333]\n",
      " [ 0.15625   ]\n",
      " [ 0.07666667]\n",
      " [ 0.2625    ]\n",
      " [ 0.22222222]\n",
      " [ 0.0625    ]\n",
      " [-0.08636364]\n",
      " [ 0.18083333]\n",
      " [ 0.        ]\n",
      " [ 0.09970238]\n",
      " [ 0.22166667]\n",
      " [ 0.095     ]\n",
      " [ 0.08848485]\n",
      " [ 0.09333333]\n",
      " [ 0.07238095]\n",
      " [-0.175     ]\n",
      " [ 0.03541667]\n",
      " [ 0.17424242]\n",
      " [ 0.11      ]\n",
      " [ 0.09583333]\n",
      " [ 0.16805556]\n",
      " [ 0.06041667]\n",
      " [ 0.19410173]\n",
      " [ 0.        ]\n",
      " [ 0.28541667]\n",
      " [ 0.25      ]\n",
      " [ 0.16369048]\n",
      " [ 0.14166667]\n",
      " [ 0.21875   ]\n",
      " [ 0.2       ]\n",
      " [ 0.18050964]\n",
      " [ 0.29166667]\n",
      " [ 0.        ]\n",
      " [-0.02588745]\n",
      " [ 0.23224638]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.07935606]\n",
      " [ 0.15      ]\n",
      " [ 0.25      ]\n",
      " [ 0.025     ]\n",
      " [ 0.12      ]\n",
      " [-0.078125  ]\n",
      " [-0.071875  ]\n",
      " [-0.08518518]\n",
      " [-1.        ]\n",
      " [ 0.14895833]\n",
      " [ 0.01333333]\n",
      " [ 0.2125    ]\n",
      " [ 0.44      ]\n",
      " [ 0.0125    ]\n",
      " [ 0.06944444]\n",
      " [ 0.12857143]\n",
      " [ 0.04375   ]\n",
      " [ 0.23459208]\n",
      " [ 0.13928571]\n",
      " [ 0.6       ]\n",
      " [ 0.515     ]\n",
      " [-0.13645833]\n",
      " [ 0.25208333]\n",
      " [ 0.28928571]\n",
      " [ 0.13125   ]\n",
      " [ 0.10476191]\n",
      " [ 0.2       ]\n",
      " [ 0.22857143]\n",
      " [ 0.21808036]\n",
      " [ 0.5       ]\n",
      " [ 0.01882716]\n",
      " [ 0.40333333]\n",
      " [ 0.1       ]\n",
      " [ 0.45833333]\n",
      " [ 0.18095238]\n",
      " [ 0.04791667]\n",
      " [ 0.07058823]\n",
      " [ 0.06924242]\n",
      " [ 0.02222222]\n",
      " [ 0.03629704]\n",
      " [-0.15555556]\n",
      " [-0.05      ]\n",
      " [ 0.23579545]\n",
      " [-0.5       ]\n",
      " [ 0.00449495]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.13863636]\n",
      " [-0.034375  ]\n",
      " [ 0.        ]\n",
      " [-0.66666667]\n",
      " [ 0.14583333]\n",
      " [ 0.10871212]\n",
      " [ 0.15659341]\n",
      " [-0.02630386]\n",
      " [-0.00779221]\n",
      " [ 0.6       ]\n",
      " [-0.125     ]\n",
      " [ 0.13333333]\n",
      " [ 0.25      ]\n",
      " [ 0.06966667]\n",
      " [ 0.1       ]\n",
      " [ 0.0375    ]\n",
      " [ 0.00595238]\n",
      " [ 0.01871693]\n",
      " [ 0.10548611]\n",
      " [ 0.259375  ]\n",
      " [ 0.        ]\n",
      " [ 0.2       ]\n",
      " [ 0.11470058]\n",
      " [ 0.06471861]\n",
      " [ 0.1694697 ]\n",
      " [ 0.20558036]\n",
      " [ 0.52      ]\n",
      " [ 0.06595238]\n",
      " [ 0.075     ]\n",
      " [ 0.22857143]\n",
      " [-0.03333333]\n",
      " [ 0.06666667]\n",
      " [-0.01458333]\n",
      " [ 0.1527972 ]\n",
      " [ 0.11071429]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.05277778]\n",
      " [-0.046875  ]\n",
      " [-0.00333333]\n",
      " [ 0.18229167]\n",
      " [ 0.0476087 ]\n",
      " [ 0.28214286]\n",
      " [ 0.0875    ]\n",
      " [-0.07777778]\n",
      " [ 0.26944444]\n",
      " [ 0.01      ]\n",
      " [-0.04466667]\n",
      " [ 0.14404762]\n",
      " [ 0.45      ]\n",
      " [ 0.09761905]\n",
      " [ 0.175     ]\n",
      " [-0.03333333]\n",
      " [ 0.45      ]\n",
      " [ 0.06428571]\n",
      " [ 0.1       ]\n",
      " [ 0.20767196]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.26346154]\n",
      " [ 0.14      ]\n",
      " [ 0.45833333]\n",
      " [-0.125     ]\n",
      " [ 0.11583333]\n",
      " [ 0.00476431]\n",
      " [ 0.17777778]\n",
      " [ 0.15833333]\n",
      " [-0.14861111]\n",
      " [-0.16666667]\n",
      " [ 0.06944444]\n",
      " [ 0.20857143]\n",
      " [ 0.05404762]\n",
      " [-0.04378157]\n",
      " [ 0.15170068]\n",
      " [ 0.125     ]\n",
      " [ 0.08374242]\n",
      " [ 0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.25909091]\n",
      " [ 0.185     ]\n",
      " [ 0.03592558]\n",
      " [ 0.22777778]\n",
      " [ 0.11308081]\n",
      " [ 0.17291667]\n",
      " [-0.25      ]\n",
      " [-0.65      ]\n",
      " [-0.11777778]\n",
      " [ 0.02380952]\n",
      " [ 0.        ]\n",
      " [ 0.30833333]\n",
      " [-0.015     ]\n",
      " [ 0.09393939]\n",
      " [ 0.0625    ]\n",
      " [ 0.13809524]\n",
      " [ 0.15333333]\n",
      " [-0.04356061]\n",
      " [ 0.09402597]\n",
      " [ 0.2147549 ]\n",
      " [ 0.3       ]\n",
      " [ 0.20189349]\n",
      " [ 0.28333333]\n",
      " [-0.35      ]\n",
      " [-0.1075    ]\n",
      " [ 0.45      ]\n",
      " [ 0.10555556]\n",
      " [ 0.3       ]\n",
      " [ 0.07052083]\n",
      " [ 0.1225    ]\n",
      " [ 0.17083333]\n",
      " [ 0.2       ]\n",
      " [ 0.06428571]\n",
      " [ 0.02579365]\n",
      " [-1.        ]\n",
      " [ 0.25      ]\n",
      " [ 0.28583333]\n",
      " [ 0.16176471]\n",
      " [ 0.23333333]\n",
      " [ 0.01369048]\n",
      " [-0.45      ]\n",
      " [ 0.27575758]\n",
      " [ 0.21666667]\n",
      " [ 0.01111111]\n",
      " [ 0.08416667]\n",
      " [-0.01333333]\n",
      " [ 0.19284512]\n",
      " [ 0.16190476]\n",
      " [ 0.01715007]\n",
      " [ 0.01875   ]\n",
      " [ 0.15      ]\n",
      " [ 0.        ]\n",
      " [ 0.04785902]\n",
      " [ 0.20166667]\n",
      " [ 0.17142857]\n",
      " [ 0.28958333]\n",
      " [-0.04523809]\n",
      " [-0.01464646]\n",
      " [ 0.0625    ]\n",
      " [ 0.02166667]\n",
      " [ 0.4       ]\n",
      " [-0.03916667]\n",
      " [ 0.5       ]\n",
      " [-0.55      ]\n",
      " [ 0.02060606]\n",
      " [ 0.10833333]\n",
      " [ 0.14526515]\n",
      " [ 0.275     ]\n",
      " [ 0.16666667]\n",
      " [ 0.55      ]\n",
      " [ 0.05552083]\n",
      " [-0.06372549]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.01277778]\n",
      " [ 0.28888889]\n",
      " [ 0.375     ]\n",
      " [-0.31833333]\n",
      " [ 0.46666667]]\n",
      "X_test:  [[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]]\n",
      "y_test:  [[ 0.275     ]\n",
      " [ 0.00555556]\n",
      " [ 0.13076923]\n",
      " [ 0.10504329]\n",
      " [ 0.25694444]\n",
      " [ 0.09285714]\n",
      " [-0.04166667]\n",
      " [ 0.125     ]\n",
      " [ 0.09675698]\n",
      " [ 0.5       ]\n",
      " [-0.01186526]\n",
      " [ 0.26666667]\n",
      " [ 0.06435185]\n",
      " [ 0.19027778]\n",
      " [-0.4       ]\n",
      " [ 0.18450635]\n",
      " [ 0.15      ]\n",
      " [ 0.24404762]\n",
      " [ 0.34545455]\n",
      " [-0.025     ]\n",
      " [ 0.2125    ]\n",
      " [ 0.1030303 ]\n",
      " [ 0.44444444]\n",
      " [-0.55555556]\n",
      " [ 0.4       ]\n",
      " [ 0.2765873 ]\n",
      " [ 0.13026245]\n",
      " [ 0.02453704]\n",
      " [ 0.15948162]\n",
      " [ 0.33888889]\n",
      " [ 0.08458333]\n",
      " [ 0.20160256]\n",
      " [ 0.121875  ]\n",
      " [ 0.19820513]\n",
      " [ 0.06428571]\n",
      " [ 0.09419643]\n",
      " [ 0.19888889]\n",
      " [ 0.1537037 ]\n",
      " [ 0.15208333]\n",
      " [ 0.        ]\n",
      " [ 0.38333333]\n",
      " [-0.2       ]\n",
      " [ 0.28571429]\n",
      " [-0.225     ]\n",
      " [ 0.33333333]\n",
      " [-0.29166667]\n",
      " [ 0.05769231]\n",
      " [ 0.01944444]\n",
      " [ 0.675     ]\n",
      " [ 0.09545455]\n",
      " [-0.17638889]\n",
      " [ 0.46666667]\n",
      " [ 0.07967607]\n",
      " [-0.2       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.06527778]\n",
      " [ 0.21645833]\n",
      " [ 0.2575    ]\n",
      " [ 0.12380952]\n",
      " [ 0.01636905]\n",
      " [ 0.        ]\n",
      " [ 0.18333333]\n",
      " [ 0.25      ]\n",
      " [ 0.1625    ]\n",
      " [ 0.56666667]\n",
      " [ 0.155     ]\n",
      " [ 0.44      ]\n",
      " [ 0.3       ]\n",
      " [-0.01214286]\n",
      " [ 0.07142857]\n",
      " [-0.3625    ]\n",
      " [ 0.0625    ]\n",
      " [-0.31666667]\n",
      " [ 0.47916667]\n",
      " [ 0.06666667]\n",
      " [-0.20833333]\n",
      " [ 0.        ]\n",
      " [ 0.17381245]\n",
      " [ 0.07795056]\n",
      " [-0.14583333]\n",
      " [ 0.03125   ]\n",
      " [ 0.04494949]\n",
      " [ 0.11909091]\n",
      " [ 0.07944444]\n",
      " [-0.0625    ]\n",
      " [-0.1       ]\n",
      " [ 0.01136364]\n",
      " [ 0.10277778]\n",
      " [ 0.02777778]\n",
      " [ 0.        ]\n",
      " [ 0.08863636]]\n"
     ]
    }
   ],
   "source": [
    "# now let's try a prediction based on Q40\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = model_selection.train_test_split(NLPdata[:,1], NLPdata[:,2], train_size=0.75,test_size=0.25, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print (\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0428\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14092f280>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, batch_size=10, epochs=10, verbose=1, validation_data=(X_test2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04280411824584007"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2, y_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 4, 7, 4, 9, 4, 9, 7, 4, 4, 9, 9, 4, 4, 9, 9, 4, 4, 9, 7, 7,\n",
       "       4, 4, 7, 7, 4, 7, 9, 4, 9, 1, 4, 4, 4, 4, 4, 4, 9, 7, 9, 4, 9, 9,\n",
       "       4, 7, 9, 4, 1, 4, 4, 4, 4, 9, 9, 4, 7, 7, 7, 9, 4, 9, 7, 7, 4, 9,\n",
       "       9, 4, 4, 9, 7, 9, 9, 7, 9, 4, 4, 9, 9, 7, 4, 7, 9, 9, 9, 4, 4, 4,\n",
       "       4, 9, 7, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test2, batch_size=10)\n",
    "model.predict_classes(X_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 9, 9, 4, 9, 5, 9, 9, 4, 9, 4, 9, 4, 2, 4, 9, 4, 4, 9, 4, 9,\n",
       "       4, 2, 4, 4, 9, 9, 4, 4, 9, 4, 9, 4, 9, 9, 4, 4, 9, 9, 4, 5, 4, 5,\n",
       "       4, 2, 9, 9, 4, 9, 5, 4, 9, 5, 9, 9, 5, 4, 4, 9, 9, 9, 4, 4, 4, 4,\n",
       "       4, 4, 4, 9, 9, 2, 9, 2, 4, 9, 5, 9, 4, 9, 5, 9, 9, 9, 9, 5, 5, 9,\n",
       "       9, 9, 9, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(y_test2, batch_size=10)\n",
    "model.predict_classes(y_test2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10038743 0.1005327  0.10005388 0.10029481 0.10021456 0.09993967\n",
      "  0.10001431 0.09881385 0.10000346 0.09974536]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10038742 0.1005327  0.10005388 0.1002948  0.10021456 0.09993968\n",
      "  0.10001431 0.09881384 0.10000346 0.09974536]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033736 0.09750504 0.09817898\n",
      "  0.09923382 0.10880695 0.10137435 0.09699066]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033736 0.09750504 0.09817898\n",
      "  0.09923382 0.10880695 0.10137435 0.09699066]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09968793 0.09956505 0.10005908 0.10033149 0.0988657  0.09907065\n",
      "  0.0996386  0.10370601 0.10070203 0.0983735 ]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.10106185 0.10147966 0.10001903 0.10022839 0.1015517  0.10078646\n",
      "  0.10036168 0.09412455 0.09928028 0.10110639]\n",
      " [0.10171172 0.10240626 0.0999556  0.1001334  0.10287727 0.10161135\n",
      "  0.10068144 0.08963215 0.09853414 0.10245668]\n",
      " [0.09985018 0.0992253  0.10083149 0.09952573 0.10152185 0.10302215\n",
      "  0.10120422 0.091053   0.09977868 0.10398736]\n",
      " [0.09821189 0.09756654 0.09997615 0.10031132 0.09613249 0.09726439\n",
      "  0.09879922 0.11412244 0.10201869 0.09559687]\n",
      " [0.0989629  0.0985764  0.10003351 0.10033737 0.09750503 0.09817898\n",
      "  0.09923381 0.10880693 0.10137435 0.09699067]]\n"
     ]
    }
   ],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new) # do I need the .round(2)?\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict values test objects\n",
    "X_new = X_test2\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x140626c10>,\n",
       " <matplotlib.lines.Line2D at 0x140626a30>,\n",
       " <matplotlib.lines.Line2D at 0x140626ac0>,\n",
       " <matplotlib.lines.Line2D at 0x140626400>,\n",
       " <matplotlib.lines.Line2D at 0x140023430>,\n",
       " <matplotlib.lines.Line2D at 0x140023940>,\n",
       " <matplotlib.lines.Line2D at 0x140023460>,\n",
       " <matplotlib.lines.Line2D at 0x1400238b0>,\n",
       " <matplotlib.lines.Line2D at 0x140023e20>,\n",
       " <matplotlib.lines.Line2D at 0x1405f0a60>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,92,92)\n",
    "y1 = y_test\n",
    "y2 = y_proba\n",
    "plt.figure(figsize=(12,6))\n",
    "#plt.plot(x,y1, 'o')\n",
    "plt.plot(x,y2, 'x', c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
